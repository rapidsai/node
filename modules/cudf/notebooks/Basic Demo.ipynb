{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple ETL / Exploration with node-rapids\n",
    "\n",
    "This notebook will demonstrate how basic APIs from `node-rapids` ([GitHub](https://github.com/rapidsai/node-rapids), [docs](https://rapidsai.github.io/node-rapids/)) may be used to load and process data from the GPU in Node.\n",
    "\n",
    "First, we load the cudf module from `node-rapids`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "var cudf = require(\"@rapidsai/cudf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to look at the 1.5 Gb [US Accidents (Dec 20) dataset from Kaggle](https://www.kaggle.com/sobhanmoosavi/us-accidents?select=US_Accidents_Dec20.csv). First we need to define load the CSV using `readCSV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readCSV: 5.340s\n"
     ]
    }
   ],
   "source": [
    "console.time(\"readCSV\")\n",
    "df = cudf.DataFrame.readCSV({\n",
    "    header: 0,\n",
    "    sourceType: 'files',\n",
    "    sources: [\"modules/cudf/notebooks/data/US_Accidents_Dec20.csv\"]\n",
    "});\n",
    "console.timeEnd(\"readCSV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the CSV into a GPU DataFrame `df` we can look at some basic information like number of rows and columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 4229394\n",
      "Number of cols: 49\n"
     ]
    }
   ],
   "source": [
    "console.log(\"Number of rows:\", df.numRows)\n",
    "console.log(\"Number of cols:\", df.numColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a quick look at the top of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ID   Source   TMC Severity          Start_Time            End_Time Start_Lat  Start_Lng End_Lat End_Lng Distance(mi)                                        Description Number                    Street Side         City     County State    Zipcode Country   Timezone Airport_Code   Weather_Timestamp Temperature(F) Wind_Chill(F) Humidity(%) Pressure(in) Visibility(mi) Wind_Direction Wind_Speed(mph) Precipitation(in) Weather_Condition Amenity  Bump Crossing Give_Way Junction No_Exit Railway Roundabout Station  Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight Nautical_Twilight Astronomical_Twilight\n",
      "A-1 MapQuest 201.0        3 2016-02-08 05:46:00 2016-02-08 11:00:00 39.865147 -84.058723    null    null         0.01                                                ...   null                    I-70 E    R       Dayton Montgomery    OH      45424      US US/Eastern         KFFO 2016-02-08 05:58:00           36.9          null        91.0        29.68           10.0           Calm            null              0.02        Light Rain   false false    false    false    false   false   false      false   false false           false          false        false          Night          Night             Night                 Night\n",
      "A-2 MapQuest 201.0        2 2016-02-08 06:07:59 2016-02-08 06:37:59 39.928059 -82.831184    null    null         0.01 Accident on Brice Rd at Tussing Rd. Expect delays. 2584.0                  Brice Rd    L Reynoldsburg   Franklin    OH 43068-3402      US US/Eastern         KCMH 2016-02-08 05:51:00           37.9          null       100.0        29.65           10.0           Calm            null               0.0        Light Rain   false false    false    false    false   false   false      false   false false           false          false        false          Night          Night             Night                   Day\n",
      "A-3 MapQuest 201.0        2 2016-02-08 06:49:27 2016-02-08 07:19:27 39.063148 -84.032608    null    null         0.01                                                ...   null            State Route 32    R Williamsburg   Clermont    OH      45176      US US/Eastern         KI69 2016-02-08 06:56:00           36.0          33.3       100.0        29.67           10.0             SW             3.5              null          Overcast   false false    false    false    false   false   false      false   false false           false           true        false          Night          Night               Day                   Day\n",
      "A-4 MapQuest 201.0        3 2016-02-08 07:23:34 2016-02-08 07:53:34 39.747753 -84.205582    null    null         0.01                                                ...   null                    I-75 S    R       Dayton Montgomery    OH      45417      US US/Eastern         KDAY 2016-02-08 07:38:00           35.1          31.0        96.0        29.64            9.0             SW             4.6              null     Mostly Cloudy   false false    false    false    false   false   false      false   false false           false          false        false          Night            Day               Day                   Day\n",
      "A-5 MapQuest 201.0        2 2016-02-08 07:39:07 2016-02-08 08:09:07 39.627781 -84.188354    null    null         0.01                                                ...   null Miamisburg Centerville Rd    R       Dayton Montgomery    OH      45459      US US/Eastern         KMGY 2016-02-08 07:53:00           36.0          33.3        89.0        29.65            6.0             SW             3.5              null     Mostly Cloudy   false false    false    false    false   false   false      false   false false           false           true        false            Day            Day               Day                   Day\n",
      "\n"
     ]
    }
   ],
   "source": [
    "console.log(df.head().toString({maxColumns: 0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this data set has lots of columns we don't really care about. We can pare things down using the `Datafame.drop` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var df = df.drop([\n",
    "    'Civil_Twilight', 'Nautical_Twilight', 'Astronomical_Twilight', 'Wind_Speed(mph)', 'Wind_Direction', 'Wind_Chill', 'Humidity(50)', 'Sunrise_Sunset',\n",
    "    'Pressure', 'Amenity', 'Bump', 'Give_Way', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Traffic_Calming', 'Turning_Loop', 'Timezone', 'Crossing', 'Stop', 'Traffic_Signal', 'Junction', 'Number', 'Side', 'County',\n",
    "    'Airport_Code', 'TMC', 'Start_Time', 'End_Time', 'Start_Lat', 'Start_Lng', 'End_Lat', 'End_Lng', 'Street', 'Country', 'Zipcode', 'Distance(mi)', 'Wind_Chill(F)', 'Pressure(in)', 'Humidity(%)']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  'ID',\n",
       "  'Source',\n",
       "  'Severity',\n",
       "  'Description',\n",
       "  'City',\n",
       "  'State',\n",
       "  'Weather_Timestamp',\n",
       "  'Temperature(F)',\n",
       "  'Visibility(mi)',\n",
       "  'Precipitation(in)',\n",
       "  'Weather_Condition'\n",
       "]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are a bit more manageable now (but still need a wide screen to see all the columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ID   Source Severity                                        Description         City State   Weather_Timestamp Temperature(F) Visibility(mi) Precipitation(in) Weather_Condition\n",
      "A-1 MapQuest        3                                                ...       Dayton    OH 2016-02-08 05:58:00           36.9           10.0              0.02        Light Rain\n",
      "A-2 MapQuest        2 Accident on Brice Rd at Tussing Rd. Expect delays. Reynoldsburg    OH 2016-02-08 05:51:00           37.9           10.0               0.0        Light Rain\n",
      "A-3 MapQuest        2                                                ... Williamsburg    OH 2016-02-08 06:56:00           36.0           10.0              null          Overcast\n",
      "A-4 MapQuest        3                                                ...       Dayton    OH 2016-02-08 07:38:00           35.1            9.0              null     Mostly Cloudy\n",
      "A-5 MapQuest        2                                                ...       Dayton    OH 2016-02-08 07:53:00           36.0            6.0              null     Mostly Cloudy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "console.log(df.head().toString({maxColumns: 0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min temp: -89\n",
      "Max temp: 203\n"
     ]
    }
   ],
   "source": [
    "temp = df.get('Temperature(F)')\n",
    "console.log(\"Min temp:\", temp.min())\n",
    "console.log(\"Max temp:\", temp.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the temperature values are clearly bad data, let's restrict the datafame to a more reasonable range. The `lt` and `gt` unary operators return a boolean mask where values are less or greater than ven values, respectively. These masks can be combined with the `logical_or` operator and then passed to `DataFrame.gather` to restrict to only the valid rows we care about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter: 32.037ms\n"
     ]
    }
   ],
   "source": [
    "temp = df.get('Temperature(F)')\n",
    "\n",
    "console.time(\"filter\")\n",
    "valid_temps = temp.lt(120).logicalAnd(temp.gt(-30))\n",
    "df = df.filter(valid_temps)\n",
    "console.timeEnd(\"filter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above how long filtering the full 1.5 Gb data set took. Below we can verify that that filtered data only has values in the specified range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New number of rows: 4139552\n",
      "New min temp: -29.9\n",
      "New max temp: 119\n"
     ]
    }
   ],
   "source": [
    "temp = df.get('Temperature(F)')\n",
    "\n",
    "console.log(\"New number of rows:\", df.numRows)\n",
    "console.log(\"New min temp:\", temp.min())\n",
    "console.log(\"New max temp:\", temp.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we might want to examine is the grouping of weather conditions. The original dataframe has very fine-grained weather conditions. e.g \"Fog\" vd \"Shallow Fog\", as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Blowing Dust\",\"Blowing Dust / Windy\",\"Blowing Sand\",\"Blowing Snow\",\"Blowing Snow / Windy\",\"Clear\",\"Cloudy\",\"Cloudy / Windy\",\"Drifting Snow\",\"Drizzle\",\"Drizzle / Windy\",\"Drizzle and Fog\",\"Dust Whirls\",\"Fair\",\"Fair / Windy\",\"Fog\",\"Fog / Windy\",\"Freezing Drizzle\",\"Freezing Rain\",\"Freezing Rain / Windy\",\"Funnel Cloud\",\"Hail\",\"Haze\",\"Haze / Windy\",\"Heavy Blowing Snow\",\"Heavy Drizzle\",\"Heavy Freezing Drizzle\",\"Heavy Freezing Rain\",\"Heavy Ice Pellets\",\"Heavy Rain\",\"Heavy Rain / Windy\",\"Heavy Rain Shower\",\"Heavy Rain Showers\",\"Heavy Sleet\",\"Heavy Smoke\",\"Heavy Snow\",\"Heavy Snow / Windy\",\"Heavy Snow with Thunder\",\"Heavy T-Storm\",\"Heavy T-Storm / Windy\",\"Heavy Thunderstorms and Rain\",\"Heavy Thunderstorms and Snow\",\"Heavy Thunderstorms with Small Hail\",\"Ice Pellets\",\"Light Blowing Snow\",\"Light Drizzle\",\"Light Drizzle / Windy\",\"Light Fog\",\"Light Freezing Drizzle\",\"Light Freezing Fog\",\"Light Freezing Rain\",\"Light Freezing Rain / Windy\",\"Light Hail\",\"Light Haze\",\"Light Ice Pellets\",\"Light Rain\",\"Light Rain / Windy\",\"Light Rain Shower\",\"Light Rain Shower / Windy\",\"Light Rain Showers\",\"Light Rain with Thunder\",\"Light Sleet\",\"Light Sleet / Windy\",\"Light Snow\",\"Light Snow / Windy\",\"Light Snow Grains\",\"Light Snow Shower\",\"Light Snow Showers\",\"Light Snow and Sleet\",\"Light Snow and Sleet / Windy\",\"Light Snow with Thunder\",\"Light Thunderstorm\",\"Light Thunderstorms and Rain\",\"Light Thunderstorms and Snow\",\"Low Drifting Snow\",\"Mist\",\"Mostly Cloudy\",\"Mostly Cloudy / Windy\",\"N/A Precipitation\",\"Overcast\",\"Partial Fog\",\"Partial Fog / Windy\",\"Partly Cloudy\",\"Partly Cloudy / Windy\",\"Patches of Fog\",\"Patches of Fog / Windy\",\"Rain\",\"Rain / Windy\",\"Rain Shower\",\"Rain Showers\",\"Rain and Sleet\",\"Sand / Dust Whirls Nearby\",\"Sand / Dust Whirlwinds\",\"Sand / Dust Whirlwinds / Windy\",\"Scattered Clouds\",\"Shallow Fog\",\"Showers in the Vicinity\",\"Sleet\",\"Sleet / Windy\",\"Small Hail\",\"Smoke\",\"Smoke / Windy\",\"Snow\",\"Snow / Windy\",\"Snow Grains\",\"Snow Showers\",\"Snow and Sleet\",\"Snow and Sleet / Windy\",\"Snow and Thunder\",\"Squalls\",\"Squalls / Windy\",\"T-Storm\",\"T-Storm / Windy\",\"Thunder\",\"Thunder / Windy\",\"Thunder / Wintry Mix\",\"Thunder / Wintry Mix / Windy\",\"Thunder and Hail\",\"Thunder and Hail / Windy\",\"Thunder in the Vicinity\",\"Thunderstorm\",\"Thunderstorms and Rain\",\"Thunderstorms and Snow\",\"Tornado\",\"Volcanic Ash\",\"Widespread Dust\",\"Widespread Dust / Windy\",\"Wintry Mix\",\"Wintry Mix / Windy\"]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_groups = df.groupBy({by: \"Weather_Condition\"})\n",
    "JSON.stringify(weather_groups.nth(0).get(\"Weather_Condition\").toArrow().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Cudf's GPU regex functions to get some quick counts of more generic weather categories. The `Series.containsRe` method will return a boolean mask that is true wherever the series value matches the regex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regex: 143.383ms\n"
     ]
    }
   ],
   "source": [
    "weather = df.get(\"Weather_Condition\")\n",
    "\n",
    "console.time(\"regex\")\n",
    "clouds_mask = weather.containsRe(\"Cloud|Overcast\");\n",
    "rain_mask = weather.containsRe(\"Rain|T-Storm|Thunderstorm|Squalls|Drizzle\");\n",
    "snow_mask = weather.containsRe(\"Snow\")\n",
    "fog_mask = weather.containsRe(\"Fog\")\n",
    "ice_mask = weather.containsRe(\"Ice|Hail|Freezing|Sleet\")\n",
    "particulate_mask = weather.containsRe(\"Dust|Smoke|Sand\")\n",
    "console.timeEnd(\"regex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorization above is not necessarily exlcusive, and categories may overlap, but we can see how many accidents had a category involved by summing each mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity with clouds     : 1889173\n",
      "Severity with rain       : 325042\n",
      "Severity with snow       : 67902\n",
      "Severity with fog        : 51700\n",
      "Severity with particulate: 8789\n",
      "Severity with ice        : 4688\n",
      "sum: 11.89ms\n"
     ]
    }
   ],
   "source": [
    "console.time(\"sum\")\n",
    "console.log(\"Severity with clouds     :\", clouds_mask.sum())\n",
    "console.log(\"Severity with rain       :\", rain_mask.sum())\n",
    "console.log(\"Severity with snow       :\", snow_mask.sum())\n",
    "console.log(\"Severity with fog        :\", fog_mask.sum())\n",
    "console.log(\"Severity with particulate:\", particulate_mask.sum())\n",
    "console.log(\"Severity with ice        :\", ice_mask.sum())\n",
    "console.timeEnd(\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be interested to look filter by these subsets to see the average severity when each category is involved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severity with clouds     : 2.3208912047758465\n",
      "Severity with rain       : 2.3520591185139152\n",
      "Severity with snow       : 2.402550734882625\n",
      "Severity with fog        : 2.2155319148936172\n",
      "Severity with particulate: 2.2825122311980883\n",
      "Severity with ice        : 2.476962457337884\n",
      "means: 62.381ms\n"
     ]
    }
   ],
   "source": [
    "console.time(\"means\")\n",
    "console.log(\"Severity with clouds     :\", df.filter(clouds_mask).get(\"Severity\").mean())\n",
    "console.log(\"Severity with rain       :\", df.filter(rain_mask).get(\"Severity\").mean())\n",
    "console.log(\"Severity with snow       :\", df.filter(snow_mask).get(\"Severity\").mean())\n",
    "console.log(\"Severity with fog        :\", df.filter(fog_mask).get(\"Severity\").mean())\n",
    "console.log(\"Severity with particulate:\", df.filter(particulate_mask).get(\"Severity\").mean())\n",
    "console.log(\"Severity with ice        :\", df.filter(ice_mask).get(\"Severity\").mean())\n",
    "console.timeEnd(\"means\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the most severe accidents were recorded in ice and snow conditions.\n",
    "\n",
    "Hopefully this has been a helpful introduction to Cudf in node-rapids! For more information [see the documentation](https://rapidsai.github.io/node-rapids/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "javascript"
  },
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "16.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
