{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "from math import ceil\n",
    "import graphistry as g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.read_csv('data/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv')\n",
    "pdf = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(g.hypergraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING -- TAKES A LONG TIME AND 55+ GiB OF HOST MEMORY\n",
    "h = g.hypergraph(pdf, opts={\n",
    "    'EVENTID': 'Label',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h['nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h['edges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(h['graph'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = cudf.DataFrame.from_pandas(h['nodes'][['nodeID', 'type']])\n",
    "nodes_df = cudf.DataFrame({\n",
    "    'name': nodes_df['nodeID'].astype('category'),\n",
    "    'type': nodes_df['type'].astype('category'),\n",
    "})\n",
    "\n",
    "edges_df = cudf.DataFrame.from_pandas(h['edges'][['attribID', 'Label']])\n",
    "edges_df = cudf.DataFrame({\n",
    "    'src': edges_df['attribID'].astype('category'),\n",
    "    'dst': edges_df['Label'].astype('category')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we need to pause and write to disk to avoid OOM'ing cuDF\n",
    "# def write_arrow(df, path):\n",
    "#     table = df.to_arrow()\n",
    "#     writer = pa.RecordBatchStreamWriter(path, table.schema)\n",
    "#     writer.write_table(table)\n",
    "# #     writer.write_table(pa.Table.from_batches(table.to_batches(max_chunksize=len(table) / 1000)))\n",
    "#     writer.close()\n",
    "\n",
    "# write_arrow(nodes_df, 'data/Thursday-01-03-2018_TrafficForML_CICFlowMeter.nodes.arrow')\n",
    "# write_arrow(edges_df, 'data/Thursday-01-03-2018_TrafficForML_CICFlowMeter.edges.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_cats(*cols):\n",
    "    cols = [col.astype('category') for col in cols]\n",
    "    cats = cudf \\\n",
    "        .concat([col.cat.categories for col in cols]) \\\n",
    "        .to_series().drop_duplicates(ignore_index=True) \\\n",
    "        ._column\n",
    "    codes_dtype = np.find_common_type([col.cat.codes.dtype for col in cols], [])\n",
    "    cols = [\n",
    "        col.cat._set_categories(\n",
    "            col.cat.categories, cats, is_unique=True\n",
    "        ) for col in cols\n",
    "    ]\n",
    "    return [\n",
    "        cudf.Series(cudf.core.column.build_categorical_column(\n",
    "            size=col.size,\n",
    "            offset=col.offset,\n",
    "            mask=col.base_mask,\n",
    "            ordered=col.dtype.ordered,\n",
    "            categories=col.cat().categories,\n",
    "            codes=col.cat().codes.astype(codes_dtype)\n",
    "        )) for col in cols\n",
    "    ]\n",
    "\n",
    "node_indices_col = cudf.core.index.RangeIndex(0, len(nodes_df))\n",
    "(\n",
    "    src_col,\n",
    "    dst_col,\n",
    "    node_name_col\n",
    ") = combine_cats(edges_df['src'], edges_df['dst'], nodes_df['name'])\n",
    "\n",
    "src_df = cudf.DataFrame({ 'src': node_name_col, 'id': node_indices_col })\n",
    "src_df = cudf.DataFrame({ 'src': src_col }) \\\n",
    "    .merge(src_df, on='src', how='left') \\\n",
    "    .rename({'id': 'src', 'src': 'node'})\n",
    "\n",
    "print(src_df.head())\n",
    "\n",
    "dst_df = cudf.DataFrame({ 'dst': node_name_col, 'id': node_indices_col })\n",
    "dst_df = cudf.DataFrame({ 'dst': dst_col }) \\\n",
    "    .merge(dst_df, on='dst', how='left') \\\n",
    "    .rename({'id': 'dst', 'dst': 'node'})\n",
    "\n",
    "print(dst_df.head())\n",
    "\n",
    "def type_to_color(types):\n",
    "    color_indices = cudf.Series(types.cat.codes)\n",
    "    color_palette = cudf.Series([\n",
    "        -12451426,-11583787,-12358156,-10375427,\n",
    "        -7610114,-4194305,-6752794,-5972565,\n",
    "        -5914010,-4356046,-6140066\n",
    "    ])\n",
    "    color_palettes = []\n",
    "    num_color_ids = color_indices.max() + 1\n",
    "    for i in range(ceil(num_color_ids / len(color_palette))):\n",
    "        color_palettes.append(color_palette)\n",
    "    return cudf.Series(cudf.core.column.build_categorical_column(\n",
    "        ordered=True,\n",
    "        codes=color_indices._column,\n",
    "        categories=cudf.concat(color_palettes)[:num_color_ids],\n",
    "    ).as_numerical_column(dtype=np.int32))\n",
    "\n",
    "nodes_df = cudf.DataFrame({\n",
    "    'id': node_indices_col,\n",
    "    'name': node_name_col,\n",
    "    'type': nodes_df['type'],\n",
    "    'color': type_to_color(nodes_df['type'])\n",
    "})\n",
    "\n",
    "edges_df = cudf.DataFrame({\n",
    "    'src': src_df['src'],\n",
    "    'dst': dst_df['dst'],\n",
    "})\n",
    "\n",
    "print(nodes_df.dtypes)\n",
    "print(nodes_df.head())\n",
    "\n",
    "print(edges_df.dtypes)\n",
    "print(edges_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_bundles(edges):\n",
    "    edges = edges.reset_index().rename({'index': 'eid'}, copy=False)\n",
    "    # Create a duplicate table with:\n",
    "    # * all the [src, dst] in the upper half\n",
    "    # * all the [dst, src] pairs as the lower half, but flipped so dst->src, src->dst\n",
    "    bundles = cudf.DataFrame({\n",
    "        'eid': cudf.concat([edges['eid'], edges['eid']]),\n",
    "        # concat [src, dst] into the 'src' column\n",
    "        'src': cudf.concat([edges['src'], edges['dst']]),\n",
    "        # concat [dst, src] into the 'dst' column\n",
    "        'dst': cudf.concat([edges['dst'], edges['src']])\n",
    "    })\n",
    "\n",
    "    # Group the duplicated edgelist by [src, dst] and get the min edge id.\n",
    "    # Since all the [dst, src] pairs have been flipped to [src, dst], each\n",
    "    # edge with the same [src, dst] or [dst, src] vertices will be assigned\n",
    "    # the same bundle id\n",
    "    bundles = bundles \\\n",
    "        .groupby(['src', 'dst']).agg({'eid': 'min'}) \\\n",
    "        .reset_index().rename({'eid': 'bid'}, copy=False)\n",
    "\n",
    "    # Join the bundle ids into the edgelist\n",
    "    edges = edges.merge(bundles, on=['src', 'dst'], how='inner')\n",
    "\n",
    "    # Determine each bundle's size and relative offset\n",
    "    bundles = edges['bid'].sort_values()\n",
    "    lengths = bundles.value_counts(sort=False)\n",
    "    offsets = lengths.cumsum() - lengths\n",
    "    # Join the bundle segment lengths + offsets into the edgelist\n",
    "    edges = edges.merge(cudf.DataFrame({\n",
    "        'bid': bundles.unique().reset_index(drop=True),\n",
    "        'start': offsets.reset_index(drop=True).astype(np.int32),\n",
    "        'count': lengths.reset_index(drop=True).astype(np.int32),\n",
    "    }), on='bid', how='left')\n",
    "\n",
    "    # Determine each edge's index relative to its bundle\n",
    "    edges = edges.sort_values(by='bid').reset_index(drop=True)\n",
    "    edges['index'] = cudf.core.index.RangeIndex(0, len(edges)) - edges['start']\n",
    "    edges['index'] = edges['index'].astype(np.int32)\n",
    "\n",
    "    # Re-sort the edgelist by edge id and cleanup\n",
    "    edges = edges.sort_values('eid').reset_index(drop=True)\n",
    "    edges = edges.rename({'eid': 'id'}, copy=False)\n",
    "\n",
    "    return edges[['id', 'src', 'dst', 'index', 'count']]\n",
    "\n",
    "edges_df_2 = add_edge_bundles(edges_df)\n",
    "print(edges_df_2.dtypes)\n",
    "print(edges_df_2)\n",
    "\n",
    "edges_df_2 = cudf.DataFrame({\n",
    "    'edge': cudf.core.column.NumericalColumn(edges_df_2[['src', 'dst']]\n",
    "        .reset_index(drop=True).stack().reset_index(drop=True)\n",
    "        .data, dtype=np.int32),\n",
    "    'bundle': cudf.core.column.NumericalColumn(edges_df_2[['index', 'count']]\n",
    "        .reset_index(drop=True).stack().reset_index(drop=True)\n",
    "        .data, dtype=np.int32),\n",
    "})\n",
    "\n",
    "print(edges_df_2.dtypes)\n",
    "print(edges_df_2)\n",
    "\n",
    "def write_arrow(df, path):\n",
    "    table = df.to_arrow()\n",
    "    writer = pa.RecordBatchStreamWriter(path, table.schema)\n",
    "    writer.write_table(table)\n",
    "    writer.close()\n",
    "\n",
    "write_arrow(nodes_df[['id', 'color']], 'data/01032018-webgl-nodes.arrow')\n",
    "write_arrow(edges_df[['src', 'dst']], 'data/01032018-webgl-edges.arrow')\n",
    "write_arrow(edges_df_2[['edge', 'bundle']], 'data/01032018-webgl-edgelist.arrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
